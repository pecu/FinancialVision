{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PATE.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Mount Google Drive for Loading Dataset\n","- The default working directory is at the root of google drive.\n","- You can change it by modifying the path in `os.chdir()`.\n","- `ETH_gaf.pkl` dataset should be placed under the working directory path."],"metadata":{"id":"sLgjXpRF8QkP"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-O6FsK8Ci-hY","outputId":"3e1c13b7-b579-46bc-8adc-ee16f9f58812","executionInfo":{"status":"ok","timestamp":1641901246309,"user_tz":-480,"elapsed":2303,"user":{"displayName":"A bigmoumou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-JZkHFwcCmobh6QbV9_kg98rjJshx6Ru0HYuXmA=s64","userId":"14969484968946000494"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir('/content/drive/')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Import Modules"],"metadata":{"id":"kqJ94yHz9pSQ"}},{"cell_type":"code","source":["import numpy as np\n","import pickle\n","import tensorflow as tf\n","from keras.utils import np_utils\n","from sklearn.metrics import confusion_matrix"],"metadata":{"id":"X_7FQTjY37V4","executionInfo":{"status":"ok","timestamp":1641901605216,"user_tz":-480,"elapsed":3187,"user":{"displayName":"A bigmoumou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-JZkHFwcCmobh6QbV9_kg98rjJshx6Ru0HYuXmA=s64","userId":"14969484968946000494"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Data Partition"],"metadata":{"id":"ZoSTog-m9tMD"}},{"cell_type":"code","metadata":{"id":"tW9g-nuJjI7p"},"source":["def partition_dataset(data, labels, nb_teachers, teacher_id):\n","  \"\"\"\n","  Simple partitioning algorithm that returns the right portion of the data\n","  needed by a given teacher out of a certain nb of teachers\n","  :param data: input data to be partitioned\n","  :param labels: output data to be partitioned\n","  :param nb_teachers: number of teachers in the ensemble (affects size of each\n","                      partition)\n","  :param teacher_id: id of partition to retrieve\n","  :return:\n","  \"\"\"\n","\n","  # Sanity check\n","  assert len(data) == len(labels)\n","  assert int(teacher_id) < int(nb_teachers)\n","\n","  # This will floor the possible number of batches\n","  batch_len = int(len(data) / nb_teachers)\n","\n","  # Compute start, end indices of partition\n","  start = teacher_id * batch_len\n","  end = (teacher_id+1) * batch_len\n","\n","  # Slice partition off\n","  np.random.seed(5)\n","  data_label = list(zip(data, labels))\n","  np.random.shuffle(data_label)\n","  data[:], labels[:] = zip(*data_label)\n","\n","  partition_data = data[start:end]\n","  partition_labels = labels[start:end]\n","\n","  return partition_data, partition_labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load Dataset & Model's Architecture"],"metadata":{"id":"6hD39Rfz90p5"}},{"cell_type":"code","metadata":{"id":"Qlh6L8XDjS-4"},"source":["def load_candlestick():\n","    fn = \"./ETH_gaf.pkl\"\n","    with open(fn, 'rb') as f:\n","        data = pickle.load(f)\n","    return (data['train_culr_gaf'], data['train_onehot'], data['val_culr_gaf'], data['val_onehot'], data['test_culr_gaf'], data['test_onehot'])\n","\n","def create_model():\n","    model = tf.keras.Sequential([\n","            tf.keras.layers.Conv2D(16, 2,\n","                                  strides=(1, 1),\n","                                  padding='same',\n","                                  activation='sigmoid',\n","                                  input_shape=(10, 10, 4)),\n","            \n","            tf.keras.layers.Conv2D(16, 2,\n","                                  strides=(2, 2),\n","                                  padding='same',\n","                                  activation='sigmoid'),\n","            tf.keras.layers.Flatten(),\n","            tf.keras.layers.Dense(256, activation='relu'),\n","            tf.keras.layers.Dense(8,activation=\"softmax\")\n","          ])\n","  return model\n","  \n","def training(model, train_data, train_labels, val_data, val_labels):\n","    optimizer = tf.keras.optimizers.SGD(learning_rate=0.0006, momentum= 0.9, nesterov=True)\n","    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction=tf.losses.Reduction.NONE)\n","    model = create_model()\n","    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n","    \n","    history = model.fit(train_data.astype(np.float32), train_labels.astype(np.float32),\n","          epochs=100,\n","          validation_data=(val_data.astype(np.float32), val_labels.astype(np.float32)),\n","          batch_size=100)\n","    \n","    return (model, history.history)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train Teacher Models"],"metadata":{"id":"g5KlZiZC-CIy"}},{"cell_type":"code","metadata":{"id":"ClNuhr8ej0nI"},"source":["def train_teacher (nb_teachers, teacher_id):\n","  \"\"\"\n","  This function trains a single teacher model with responds teacher's ID among an ensemble of nb_teachers\n","  models for the dataset specified.\n","  The model will be save in directory. \n","  :param nb_teachers: total number of teachers in the ensemble\n","  :param teacher_id: id of the teacher being trained\n","  :return: True if everything went well\n","  \"\"\"\n","  # Retrieve subset of data for this teacher\n","  train_data, train_labels,val_data,val_labels, test_data, test_labels = load_candlestick()\n","  data, labels = partition_dataset(train_data, train_labels, nb_teachers, teacher_id)\n","  print(\"Length of training data: \" + str(len(labels)))\n","\n","  # Define teacher checkpoint filename and full path\n","  filename2 = \"teachers/\" + str(nb_teachers) + '_teachers_' + str(teacher_id) + '.h5'\n","\n","  # Create teacher model\n","  model = create_model()\n","  model, hist = training(model, data, labels, val_data, val_labels)\n","  model.save(filename2)\n","  \n","  print(\"Saved model to disk\")\n","  return hist"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Aggregation of the PATE framework"],"metadata":{"id":"6teypaD3-Lqc"}},{"cell_type":"code","metadata":{"id":"ROPvPLGTkMli"},"source":["def labels_from_probs(probs):\n","  \"\"\"\n","  Helper function: computes argmax along last dimension of array to obtain\n","  labels (max prob or max logit value)\n","  :param probs: numpy array where probabilities or prob are on last dimension\n","  :return: array with same shape as input besides last dimension with shape 1\n","          now containing the labels\n","  \"\"\"\n","  # Compute last axis index\n","  last_axis = len(np.shape(probs)) - 1\n","  \n","  # Label is argmax over last dimension\n","  labels = np.argmax(probs, axis=last_axis)\n","\n","  # Return as np.int32\n","  return np.asarray(labels, dtype=np.int32)\n","\n","def noisy_max(prob, lap_scale):\n","  \"\"\"\n","  This aggregation mechanism takes the softmax/logit output of several models\n","  resulting from inference on identical inputs and computes the noisy-max of\n","  the votes for candidate classes to select a label for each sample: it\n","  adds Laplacian noise to label counts and returns the most frequent label.\n","  :param prob: prob or probabilities for each sample\n","  :param lap_scale: scale of the Laplacian noise to be added to counts\n","  :return: pair of result and (if clean_votes is set to True) the clean counts\n","           for each class per sample and the the original labels produced by\n","           the teachers.\n","  \"\"\"\n","  # Compute labels from prob/probs and reshape array properly\n","  labels = labels_from_probs(prob) \n","\n","  labels_shape = np.shape(labels)\n","  labels = labels.reshape((labels_shape[0], labels_shape[1]))\n","  \n","  # Initialize array to hold final labels\n","  result = np.zeros(int(labels_shape[1])) \n","\n","  # Parse each sample\n","  for i in range(int(labels_shape[1])):\n","    # Count number of votes assigned to each class\n","    label_counts = np.bincount(labels[:, i], minlength=10)\n","    \n","    # Cast in float32 to prepare before addition of Laplacian noise\n","    label_counts = np.asarray(label_counts, dtype=np.float32)\n","\n","    # Sample independent Laplacian noise for each class change the size of class in here \n","    for item in range(1):\n","      label_counts[item] += np.random.laplace(loc=0.0, scale=float(lap_scale))\n","\n","    # Result is the most frequent label\n","    result[i] = np.argmax(label_counts)\n","\n","    # Cast labels to np.int32 for compatibility with deep_cnn.py feed dictionaries\n","    result = np.asarray(result, dtype=np.int32)\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prepare Data for Student Model"],"metadata":{"id":"fmQW5hwd-egS"}},{"cell_type":"code","metadata":{"id":"ueq87KS_kYzD"},"source":["def ensemble_preds(nb_teachers, stdnt_data, num_class):\n","    \"\"\"\n","    Given a dataset, a number of teachers, and some input data, this helper\n","    function queries each teacher for predictions on the data and returns\n","    all predictions in a single array. \n","    :param nb_teachers: number of teachers (in the ensemble) to learn from\n","    :param stdnt_data: unlabeled student training data\n","    :return: 3d array (teacher id, sample id, probability per class)\n","    \"\"\"\n","    # Compute shape of array that will hold probabilities produced by each\n","    # teacher, for each training point, and each output class\n","    result_shape = (nb_teachers, len(stdnt_data), num_class)\n","\n","    # Create array that will hold result\n","    result = np.zeros(result_shape, dtype=np.float32)\n","\n","    # Get predictions from each teacher\n","    for teacher_id in range(nb_teachers):\n","        # Compute path of weight file for teacher model with ID teacher_id\n","        filename2 = \"teachers/\" + str(nb_teachers) + '_teachers_' + str(teacher_id) + '.h5'\n","        model = tf.keras.models.load_model(filename2)\n","        # Get predictions on our training data and store in result array\n","        result[teacher_id] = model.predict(stdnt_data)  \n","\n","        # This can take a while when there are a lot of teachers so output status\n","        print(\"Computed Teacher \" + str(teacher_id) + \"predictions\")\n","\n","    return result\n","\n","def prepare_student_data(test_data,nb_teachers,lap_scale):\n","    \"\"\"\n","    Takes a dataset name and the size of the teacher ensemble and prepares\n","    training data for the student model\n","    :param dataset: string corresponding to mnist, cifar10, or svhn\n","    :param nb_teachers: number of teachers (in the ensemble) to learn from\n","    :Param: lap_scale: scale of the Laplacian noise added for privacy\n","    :return: pairs of (data, labels) to be used for student training and testing\n","    \"\"\"\n","    # Compute teacher predictions for student training data\n","    teachers_preds = ensemble_preds(nb_teachers, test_data, 8)\n","\n","    # Aggregate teacher predictions to get student training labels\n","    stdnt_labels = noisy_max(teachers_preds, lap_scale)\n","    print('stdnt_labels')\n","    stdnt_labels = np_utils.to_categorical(stdnt_labels, 8)\n","    print(len(stdnt_labels))\n","    print(stdnt_labels.shape)\n","\n","    # Store unused part of test set for use as a test set after student training\n","    return stdnt_labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train Student Model"],"metadata":{"id":"ArDThOnk-ovN"}},{"cell_type":"code","metadata":{"id":"WFe_L7Odk9Vx"},"source":["def train_student(nb_teachers,lap):\n","    \"\"\"\n","    This function trains a student using predictions made by an ensemble of\n","    teachers. The student and teacher models are trained using the same\n","    neural network architecture.\n","    :param nb_teachers: number of teachers (in the ensemble) to learn from\n","    :return: True if student training went well\n","    \"\"\"\n","    # you need to change the address of get_dataset() manuly \n","    train_data, train_labels, val_data, val_labels, test_data, test_labels = load_candlestick()\n","    \n","    # Call helper function to prepare student data using teacher predictions\n","    stdnt_labels= prepare_student_data(train_data, nb_teachers, lap)\n","    \n","    # labels acc \n","    labels_result_cm = confusion_matrix(train_labels.argmax(axis=1), stdnt_labels.argmax(axis=1), labels=range(8))\n","    count = 0\n","    for r in range(8):\n","      count += labels_result_cm[r, r]\n","    label_acc = count/np.sum(labels_result_cm)\n","    print('labels accuracy:', label_acc)\n","\n","    # Start student training\n","    model, hist = None, None\n","    model, hist = training(model, train_data, stdnt_labels, val_data, val_labels)\n","    \n","    test_pred = model.predict(test_data)\n","    test_pred = np.argmax(test_pred, axis=1)\n","    test_true = np.argmax(test_labels, axis=1)\n","    test_result_cm = confusion_matrix(test_true, test_pred, labels=range(8))\n","    print(test_result_cm)\n","    count = 0\n","    for r in range(8):\n","        count += test_result_cm[r, r]\n","    test_acc = count/np.sum(test_result_cm)\n","    print('testing accuracy:', count/np.sum(test_result_cm))\n","    \n","    # Compute final checkpoint name for student\n","    print(hist)\n","    model.save(f'student_teacher{nb_teachers}_lap{lap}.h5')\n","\n","    return hist, label_acc, test_acc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Run Teacher Models Training"],"metadata":{"id":"Ruy7DE-I-yEj"}},{"cell_type":"code","metadata":{"id":"CYLSMkKDnFxS"},"source":["N = [1, 10, 20, 50]\n","for n in N:\n","  for i in range(n):\n","    train_teacher(nb_teachers=n, teacher_id=i)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Run Student Model Training"],"metadata":{"id":"ahq5_MCC-7xv"}},{"cell_type":"code","metadata":{"id":"PGHyPQNWlePR"},"source":["teachers = [1, 10, 20, 50]\n","lap = [1, 10, 30, 50, 100]\n","for l in lap:\n","  for t in teachers:\n","    history, lab_acc, t_acc = train_student(t, l)"],"execution_count":null,"outputs":[]}]}